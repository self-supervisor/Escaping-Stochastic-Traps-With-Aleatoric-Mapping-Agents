{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Noisy Environment ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize='large')\n",
    "plt.rc('ytick', labelsize='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('data')\n",
    "x_train_data, y_train_data = mndata.load_training()\n",
    "x_test_data, y_test_data = mndata.load_testing()\n",
    "\n",
    "training_steps=50000\n",
    "checkpoint_loss=1000\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)\n",
    "\n",
    "class NoisyMnistEnv:\n",
    "    def __init__(self, split, input_number_min, input_number_max, batch_size=64, seed=0):\n",
    "        self.seed = seed\n",
    "        self.split = split\n",
    "        if self.split == \"train\":\n",
    "            self.x, self.y = x_train_data, y_train_data\n",
    "        elif self.split == \"test\":\n",
    "            self.x, self.y = x_test_data, y_test_data\n",
    "        self.batch_size = batch_size\n",
    "        self.input_number_min = input_number_min\n",
    "        self.input_number_max = input_number_max\n",
    "        \n",
    "    \n",
    "    def step(self):\n",
    "        x_arr = np.zeros((self.batch_size, 28 * 28))\n",
    "        y_arr = np.zeros((self.batch_size, 28 * 28))\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            input_number = np.random.randint(self.input_number_min, self.input_number_max)\n",
    "            if input_number == 0:\n",
    "                output_number = 0\n",
    "            if input_number == 1:\n",
    "                output_number = np.random.randint(2, 10)\n",
    "            input_data = self.get_random_sample_of_number(input_number)\n",
    "            if input_number == 1:\n",
    "                output_data = self.get_random_sample_of_number(output_number)\n",
    "            elif input_number == 0:\n",
    "                output_data = input_data\n",
    "            x_arr[i] = np.array(input_data)\n",
    "            y_arr[i] = np.array(output_data)\n",
    "        return x_arr, y_arr\n",
    "    \n",
    "    def get_random_sample_of_number(self, number):\n",
    "        random_num = np.random.randint(0, len(self.y) - 1)\n",
    "        if self.y[random_num] == number:\n",
    "            return self.x[random_num]\n",
    "        else:\n",
    "            return self.get_random_sample_of_number(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist_env = NoisyMnistEnv(\"train\", 0, 2)\n",
    "x, y  = mnist_env.step()\n",
    "count = 0\n",
    "for i in zip(x,y):\n",
    "    count += 1\n",
    "    if count == 16:\n",
    "        break\n",
    "    plt.title(\"input\", fontsize=20)\n",
    "    plt.imshow(np.squeeze(i[0]).reshape(28, 28))\n",
    "    plt.show()\n",
    "    plt.title(\"output\", fontsize=20)\n",
    "    plt.imshow(np.squeeze(i[1]).reshape(28, 28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_env_zeros = NoisyMnistEnv(\"test\", 0, 1)\n",
    "x, y  = mnist_env_zeros.step()\n",
    "count = 0\n",
    "for i in zip(x,y):\n",
    "    count += 1\n",
    "    if count == 16:\n",
    "        break\n",
    "    plt.title(\"input\", fontsize=20)\n",
    "    plt.imshow(np.squeeze(i[0]).reshape(28, 28))\n",
    "    plt.show()\n",
    "    plt.title(\"output\", fontsize=20)\n",
    "    plt.imshow(np.squeeze(i[1]).reshape(28, 28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_env_ones = NoisyMnistEnv(\"test\", 1, 2)\n",
    "x, y  = mnist_env_ones.step()\n",
    "count = 0\n",
    "for i in zip(x,y):\n",
    "    count += 1\n",
    "    if count == 16:\n",
    "        break\n",
    "    plt.title(\"input\", fontsize=20)\n",
    "    plt.imshow(np.squeeze(i[0]).reshape(28, 28))\n",
    "    plt.show()\n",
    "    plt.title(\"output\", fontsize=20)\n",
    "    plt.imshow(np.squeeze(i[1]).reshape(28, 28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# from here https://github.com/L1aoXingyu/pytorch-beginner/tree/master/08-AutoEncoder\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear_1 = nn.Linear(28 * 28, 128)\n",
    "        self.linear_2 = nn.Linear(128, 128)\n",
    "        self.linear_3 = nn.Linear(128, 128)\n",
    "        self.linear_4 = nn.Linear(128, 28 * 28)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear_1(x))\n",
    "        x = F.relu(self.linear_2(x))\n",
    "        x = F.relu(self.linear_3(x))\n",
    "        x = (self.linear_4(x))\n",
    "        return x\n",
    "    \n",
    "# from here https://github.com/L1aoXingyu/pytorch-beginner/tree/master/08-AutoEncoder\n",
    "class AleatoricNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AleatoricNet, self).__init__()\n",
    "        self.linear_1 = nn.Linear(28 * 28, 128)\n",
    "        self.linear_2 = nn.Linear(128, 128)\n",
    "        self.linear_3_mu = nn.Linear(128, 128)\n",
    "        self.linear_4_mu = nn.Linear(128, 28 * 28)\n",
    "        self.linear_3_sigma = nn.Linear(128, 128)\n",
    "        self.linear_4_sigma = nn.Linear(128, 28 * 28)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear_1(x))\n",
    "        x = F.relu(self.linear_2(x))\n",
    "        mu = F.relu(self.linear_3_mu(x))\n",
    "        mu = (self.linear_4_mu(mu))\n",
    "        log_sigma = F.relu(self.linear_3_sigma(x))\n",
    "        log_sigma = (self.linear_4_sigma(log_sigma))\n",
    "        return mu, log_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repeats = 1\n",
    "\n",
    "for repeat in range(repeats):\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=0.1)\n",
    "\n",
    "    loss_list = []\n",
    "    loss_buffer = []\n",
    "    loss_list_0 = []\n",
    "    loss_list_1 = []\n",
    "    loss_buffer_0 = []\n",
    "    loss_buffer_1 = []\n",
    "    for update in tqdm(range(int(training_steps))):\n",
    "        model.train()\n",
    "        data, target = mnist_env.step()\n",
    "        data /= 255\n",
    "        target /= 255\n",
    "        data = torch.from_numpy(data).float().to(device)\n",
    "        target = torch.from_numpy(target).float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_buffer.append(loss)\n",
    "        if update % checkpoint_loss == 0:\n",
    "            loss_list.append(torch.mean(torch.stack(loss_buffer)).detach().cpu().numpy())\n",
    "            loss_buffer = []\n",
    "\n",
    "        model.eval()\n",
    "        data, target = mnist_env_zeros.step()\n",
    "        data /= 255\n",
    "        target /= 255\n",
    "        data = torch.from_numpy(data).float().to(device)\n",
    "        target = torch.from_numpy(target).float().to(device)\n",
    "        output = model(data)\n",
    "        loss_0 = F.mse_loss(output, target)\n",
    "        loss_buffer_0.append(loss_0)\n",
    "        if update % checkpoint_loss == 0:\n",
    "            loss_list_0.append(torch.mean(torch.stack(loss_buffer_0)).detach().cpu().numpy())\n",
    "            loss_buffer_0 = []\n",
    "\n",
    "        model.eval()\n",
    "        data, target = mnist_env_ones.step()\n",
    "        data /= 255\n",
    "        target /= 255\n",
    "        data = torch.from_numpy(data).float().to(device)\n",
    "        target = torch.from_numpy(target).float().to(device)\n",
    "        output = model(data)\n",
    "        loss_1 = F.mse_loss(output, target)\n",
    "        loss_buffer_1.append(loss_1)\n",
    "        if update % checkpoint_loss == 0:\n",
    "            loss_list_1.append(torch.mean(torch.stack(loss_buffer_1)).detach().cpu().numpy())\n",
    "            loss_buffer_1 = []\n",
    "\n",
    "    data, target = mnist_env.step()\n",
    "    predictions = model(torch.from_numpy(data).float().to(device)/255)\n",
    "\n",
    "    for i in range(10):\n",
    "        w=10\n",
    "        h=10\n",
    "        fig=plt.figure(figsize=(12, 12))\n",
    "        columns = 3\n",
    "        rows = 1\n",
    "        fig.add_subplot(rows, columns, 1)\n",
    "        plt.imshow(data[i].reshape(28, 28)/255, vmin=0, vmax=1)\n",
    "        plt.title(\"input state\", fontsize=20)\n",
    "\n",
    "        fig.add_subplot(rows, columns, 2)\n",
    "        plt.imshow(target[i].reshape(28, 28)/255, vmin=0, vmax=1)\n",
    "        plt.title(\"true next state\", fontsize=20)\n",
    "\n",
    "        fig.add_subplot(rows, columns, 3)\n",
    "        plt.imshow(predictions[i].detach().cpu().numpy().reshape(28, 28), vmin=0, vmax=1)\n",
    "        plt.title(\"predicted $\\mu$\", fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "    np.save(\"lost_list_0_\" + str(repeat) + \".npy\", loss_list_0)\n",
    "    np.save(\"lost_list_1_\" + str(repeat) + \".npy\", loss_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aleatoric ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for repeat in range(repeats):\n",
    "    model = AleatoricNet().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=0.1)\n",
    "    model.train()\n",
    "    loss_list_aleatoric = []\n",
    "    loss_buffer = []\n",
    "    loss_list_0_aleatoric = []\n",
    "    loss_list_1_aleatoric = []\n",
    "    loss_buffer_0 = []\n",
    "    loss_buffer_1 = []\n",
    "\n",
    "    for update in tqdm(range(int(training_steps))):\n",
    "        model.train()\n",
    "        data, target = mnist_env.step()\n",
    "        data /= 255\n",
    "        target /= 255\n",
    "        data = torch.from_numpy(data).float().to(device)\n",
    "        target = torch.from_numpy(target).float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        mu, log_sigma = model(data)\n",
    "        mse = F.mse_loss(mu, target, reduction=\"none\")\n",
    "        loss = torch.mean(torch.exp(-log_sigma) * mse + log_sigma)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_buffer.append(torch.mean(mse - torch.exp(log_sigma)))\n",
    "        if update % checkpoint_loss == 0:\n",
    "            loss_list_aleatoric.append(torch.mean(torch.stack(loss_buffer)).detach().cpu().numpy())\n",
    "            loss_buffer = []\n",
    "\n",
    "        model.eval()\n",
    "        data, target = mnist_env_zeros.step()\n",
    "        data /= 255\n",
    "        target /= 255\n",
    "        data = torch.from_numpy(data).float().to(device)\n",
    "        target = torch.from_numpy(target).float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        mu, log_sigma = model(data)\n",
    "        mse = F.mse_loss(mu, target, reduction=\"none\")\n",
    "        loss = torch.mean(torch.exp(-log_sigma) * mse + log_sigma)\n",
    "        loss_buffer_0.append(torch.mean(mse - torch.exp(log_sigma)))\n",
    "        if update % checkpoint_loss == 0:\n",
    "            loss_list_0_aleatoric.append(torch.mean(torch.stack(loss_buffer_0)).detach().cpu().numpy())\n",
    "            loss_buffer_0 = []\n",
    "\n",
    "        model.eval()\n",
    "        data, target = mnist_env_ones.step()\n",
    "        data /= 255\n",
    "        target /= 255\n",
    "        data = torch.from_numpy(data).float().to(device)\n",
    "        target = torch.from_numpy(target).float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        mu, log_sigma = model(data)\n",
    "        mse = F.mse_loss(mu, target, reduction=\"none\")\n",
    "        loss = torch.mean(torch.exp(-log_sigma) * mse + log_sigma)\n",
    "        loss_buffer_1.append(torch.mean(mse - torch.exp(log_sigma)))\n",
    "        if update % checkpoint_loss == 0:\n",
    "            loss_list_1_aleatoric.append(torch.mean(torch.stack(loss_buffer_1)).detach().cpu().numpy())\n",
    "            loss_buffer_1 = []\n",
    "\n",
    "    data, target = mnist_env.step()\n",
    "    mu, sigma = model(torch.from_numpy(data).float().to(device)/255)\n",
    "\n",
    "    for i in range(10):\n",
    "        w=10\n",
    "        h=10\n",
    "        fig=plt.figure(figsize=(12, 12))\n",
    "        columns = 4\n",
    "        rows = 1\n",
    "        fig.add_subplot(rows, columns, 1)\n",
    "        plt.imshow(data[i].reshape(28, 28)/255, vmin=0, vmax=1)\n",
    "        plt.title(\"input state\", fontsize=20)\n",
    "\n",
    "        fig.add_subplot(rows, columns, 2)\n",
    "        plt.imshow(target[i].reshape(28, 28)/255, vmin=0, vmax=1)\n",
    "        plt.title(\"true next state\", fontsize=20)\n",
    "\n",
    "        fig.add_subplot(rows, columns, 3)\n",
    "        plt.imshow(mu[i].detach().cpu().numpy().reshape(28, 28), vmin=0, vmax=1)\n",
    "        plt.title(\"predicted $\\mu$\", fontsize=20)\n",
    "\n",
    "        fig.add_subplot(rows, columns, 4)\n",
    "        plt.imshow(np.sqrt(np.exp((sigma[i].detach().cpu().numpy().reshape(28, 28)))), vmin=0, vmax=1)\n",
    "        plt.title(\"predicted $\\sigma$\", fontsize=20)\n",
    "\n",
    "        plt.show()\n",
    "    np.save(\"aleatoric_lost_list_0_\" + str(repeat) + \".npy\", loss_list_0_aleatoric)\n",
    "    np.save(\"aleatoric_lost_list_1_\" + str(repeat) + \".npy\", loss_list_1_aleatoric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data, target = mnist_env.step()\n",
    "mu, sigma = model(torch.from_numpy(data).float().to(device)/255)\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(8, 6), dpi=2000, facecolor='w', edgecolor='k')\n",
    "title_size = 40\n",
    "cmap='bone'\n",
    "\n",
    "for i in range(3):\n",
    "    w=10\n",
    "    h=10\n",
    "    fig=plt.figure(figsize=(18, 18))\n",
    "    columns = 5\n",
    "    rows = 1\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow(data[i].reshape(28, 28)/255, vmin=0, vmax=1, cmap=cmap)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0:\n",
    "        plt.title(r\"Input\", fontsize=title_size)\n",
    "    \n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow(target[i].reshape(28, 28)/255, vmin=0, vmax=1, cmap=cmap)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0:\n",
    "        plt.title(r\"Output\", fontsize=title_size)\n",
    "    \n",
    "    fig.add_subplot(rows, columns, 3)\n",
    "    plt.imshow(mu[i].detach().cpu().numpy().reshape(28, 28), vmin=0, vmax=1, cmap=cmap)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0:\n",
    "        plt.title(\"Pred. $\\mu$\", fontsize=title_size)\n",
    "    \n",
    "    fig.add_subplot(rows, columns, 4)\n",
    "    plt.imshow(np.sqrt(np.exp((sigma[i].detach().cpu().numpy().reshape(28, 28)))), vmin=0, vmax=1, cmap=cmap)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0:\n",
    "        plt.title(\"Pred. $\\sigma$\", fontsize=title_size)\n",
    "    \n",
    "    fig.add_subplot(rows, columns, 5)\n",
    "    plt.imshow(((mu[i].detach().cpu().numpy() - target[i]/255)**2).reshape(28,28) - np.exp(sigma[i].detach().cpu().numpy()).reshape(28, 28), vmin=0, vmax=1, cmap=cmap)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0:\n",
    "        plt.title(\"Error\", fontsize=title_size)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = [x * 1000 for x in list(range(len(loss_list_0_aleatoric)))]\n",
    "plt.plot(updates,loss_list_0_aleatoric,label=\"Aleatoric Net Less Stochastic\")\n",
    "plt.plot(updates,loss_list_1_aleatoric,label=\"Aleatoric Net More Stochastic\")\n",
    "plt.plot(updates,loss_list_0,label=\"Vanilla Net Less Stochastic\")\n",
    "plt.plot(updates,loss_list_1,label=\"Vanilla Net More Stochastic\")\n",
    "plt.legend(loc=\"best\", fontsize=12)\n",
    "plt.ylabel(\"Intrinsic Reward\", fontsize=15)\n",
    "plt.xlabel(\"Update step\", fontsize=15)\n",
    "plt.ylim(-0.05, 0.2)\n",
    "plt.title(\"Noisy MNIST\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import glob\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import figure\n",
    "# figure(num=None, figsize=(8, 6), dpi=1000, facecolor='w', edgecolor='k')\n",
    "# from matplotlib import rcParams\n",
    "# rcParams['axes.titlepad'] =2 \n",
    "\n",
    "# def load_files_into_arr(list_of_file_paths):\n",
    "#     all_arrs = []\n",
    "#     for a_file in list_of_file_paths:\n",
    "#         all_arrs.append(np.load(a_file))\n",
    "#     return all_arrs\n",
    "\n",
    "# def get_mean_and_std_dev(arr_of_results):\n",
    "#     return np.mean(arr_of_results, axis=0), np.std(arr_of_results, axis=0)\n",
    "\n",
    "# def plot_mean_and_std(mean, std, label):\n",
    "#     assert len(mean) == len(std)\n",
    "#     if \"stochastic\" in label:\n",
    "#         linestyle=\"-\"\n",
    "#     else:\n",
    "#         linestyle=\"--\"\n",
    "#     if \"AMA\" in label:\n",
    "#         color=\"forestgreen\"\n",
    "#     else:\n",
    "#         color=\"darkmagenta\"\n",
    "#     plt.plot(list(range(len(mean))), mean, linestyle=linestyle, label=label, color=color)\n",
    "#     x = list(range(len(mean)))\n",
    "#     plt.fill_between(x, (mean-std), (mean+std), alpha=0.2, color=color)\n",
    "\n",
    "# import glob\n",
    "# npy_files = glob.glob(\"*npy\")\n",
    "# aleatoric_stochastic = [file for file in npy_files if \"_0\" in file and \"aleatoric\" in file]\n",
    "# aleatoric_deterministic = [file for file in npy_files if \"_1\" in file and \"aleatoric\" in file]\n",
    "# vanilla_deterministic = [file for file in npy_files if \"aleatoric\" not in file and \"_0\" in file]\n",
    "# vanilla_stochastic = [file for file in npy_files if \"aleatoric\" not in file and \"_1\" in file]\n",
    "\n",
    "# list_of_file_lists =[vanilla_stochastic, vanilla_deterministic, aleatoric_stochastic, aleatoric_deterministic,]\n",
    "\n",
    "# legends = [r\"MSE stochastic\",\n",
    "#            r\"MSE deterministic\",\n",
    "#            r\"AMA stochastic\",\n",
    "#            r\"AMA deterministic\"]\n",
    "\n",
    "# colors = [\"darkmagenta\", \"forestgreen\"]\n",
    "# plt.xlim(0, 50)\n",
    "# plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "# plt.tick_params(axis='both', which='minor', labelsize=18)\n",
    "\n",
    "# for i, files in enumerate(list_of_file_lists):\n",
    "#     results = load_files_into_arr(files)\n",
    "#     mu, sigma = get_mean_and_std_dev(results)\n",
    "#     plot_mean_and_std(mu, sigma, legends[i])\n",
    "\n",
    "# plt.rc('font', family='serif')\n",
    "# plt.legend(loc=\"best\", fontsize=20)\n",
    "# plt.ylabel(\"Intrinsic Reward\", fontsize=24)\n",
    "# plt.xlabel(r\"Update Step $\\times 10 ^{3}$\", fontsize=24)\n",
    "# plt.ylim(-0.05, 0.2)\n",
    "# plt.title(\"Noisy MNIST\", fontsize=29)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
